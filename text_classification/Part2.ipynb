{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Project Phase 3 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the datasets \n",
    "#as masking datasets have more positive outcomes in my case, I would be using it for model training\n",
    "mask_data1 = pd.read_csv(\"/home/akshay/Desktop/IIT_courses/NLP/NLP_Phase3/change_org_masking.csv\")\n",
    "mask_data2 = pd.read_csv(\"/home/akshay/Desktop/IIT_courses/NLP/NLP_Phase3/twitter_masking.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Education in the Time of COVID-19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Test Kits</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID 19 IN PRISON</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get Waled Home</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make pass/fail available for Mississippi State...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0         Language Education in the Time of COVID-19  False\n",
       "1                                 COVID-19 Test Kits  False\n",
       "2                                 COVID 19 IN PRISON  False\n",
       "3                                     Get Waled Home  False\n",
       "4  Make pass/fail available for Mississippi State...  False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 2 columns):\n",
      "text     1500 non-null object\n",
      "label    1500 non-null bool\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "mask_data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>.Sprint To Develop A #COVIDVaccine â€“ // https:...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Here in the U.S. some localities have brought ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Sanitizer &amp;amp; Mask Manufacturers After Russi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>We are following all CDC guidelines through a ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>People be losing hopes on covid vaccine like i...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1195  .Sprint To Develop A #COVIDVaccine â€“ // https:...  False\n",
       "1196  Here in the U.S. some localities have brought ...   True\n",
       "1197  Sanitizer &amp; Mask Manufacturers After Russi...  False\n",
       "1198  We are following all CDC guidelines through a ...   True\n",
       "1199  People be losing hopes on covid vaccine like i...  False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 2 columns):\n",
      "text     1200 non-null object\n",
      "label    1200 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "mask_data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data \n",
    "#here, we can see that 3 unwanted columns in the dataset. So, we will concatenate the data from them and drop the columns\n",
    "#print(mask_data2.loc[2,\"label\"])\n",
    "#for i in range(0,1200):\n",
    "#    if(mask_data2.loc[p,\"label\"] != True or mask_data2.loc[p,\"label\"] != False):\n",
    "#        print(\"need changes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating both the dataframes\n",
    "#mask_data = pd.concat([mask_data1, mask_data2])\n",
    "#print(mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mask_data.iloc[2699]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting index of the dataframe \n",
    "#mask_data = mask_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mask_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1] splitting the primary dataset into train and test sets\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(mask_data1[\"text\"],mask_data1[\"label\"], test_size=0.3, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using full secodnary dataset as test dataset\n",
    "x_test2 = mask_data2[\"text\"]\n",
    "y_test2 = mask_data2[\"label\"] == 'True'\n",
    "#y_test2.dtype\n",
    "#print(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "bool\n",
      "object\n",
      "bool\n",
      "object\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "print(x_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(x_test1.dtype)\n",
    "print(y_test1.dtype)\n",
    "print(x_test2.dtype)\n",
    "print(y_test2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "450\n",
      "1050\n",
      "450\n",
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test1))\n",
    "print(len(y_train))\n",
    "print(len(y_test1))\n",
    "print(len(x_test2))\n",
    "print(len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2] Baseline Modeling - Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 2984)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 2984)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tfidf = tfidf.fit_transform(x_train_counts)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a naive bayes classifier on training dataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB().fit(x_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1_counts = count_vect.transform(x_test1)\n",
    "x_test1_tfidf = tfidf.transform(x_test1_counts)\n",
    "\n",
    "pred = nb.predict(x_test1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for txt, category in zip(x_test1, pred):\n",
    "#    print('%r => %s' % (txt, y_test1[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary = np.mean(pred == y_test1)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      1.00      0.85       313\n",
      "        True       1.00      0.20      0.33       137\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       450\n",
      "   macro avg       0.87      0.60      0.59       450\n",
      "weighted avg       0.82      0.76      0.69       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test1, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7825\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "x_test2_counts = count_vect.transform(x_test2)\n",
    "x_test2_tfidf = tfidf.transform(x_test2_counts)\n",
    "\n",
    "pred2 = nb.predict(x_test2_tfidf)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary = np.mean(pred2 == y_test2)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      1.00      0.88       939\n",
      "        True       0.00      0.00      0.00       261\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1200\n",
      "   macro avg       0.39      0.50      0.44      1200\n",
      "weighted avg       0.61      0.78      0.69      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#using SVM model on training data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None).fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using SVM model for primary dataset \n",
    "pred = svm.predict(x_test1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.8177777777777778\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary = np.mean(pred == y_test1)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7716666666666666\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred2 = svm.predict(x_test2_tfidf)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary = np.mean(pred2 == y_test2)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[307,   6],\n",
       "       [ 76,  61]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for primary test dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.confusion_matrix(y_test1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[923,  16],\n",
       "       [258,   3]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for secondary test dataset\n",
    "metrics.confusion_matrix(y_test2, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.98      0.87       939\n",
      "        True       0.16      0.01      0.02       261\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1200\n",
      "   macro avg       0.47      0.50      0.45      1200\n",
      "weighted avg       0.65      0.77      0.69      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.98      0.88       313\n",
      "        True       0.91      0.45      0.60       137\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       450\n",
      "   macro avg       0.86      0.71      0.74       450\n",
      "weighted avg       0.83      0.82      0.80       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test1, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1, random_state = 42)\n",
    "rf = rf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "#the accuracy kept on decreasing if number of estimators were increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using Random Forest model\n",
    "pred = rf.predict(x_test1_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary = np.mean(pred == y_test1)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7375\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred2 = rf.predict(x_test2_tfidf)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary = np.mean(pred2 == y_test2)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.82      0.82       313\n",
      "        True       0.59      0.61      0.60       137\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       450\n",
      "   macro avg       0.71      0.71      0.71       450\n",
      "weighted avg       0.75      0.75      0.75       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test1, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.89      0.84       939\n",
      "        True       0.32      0.19      0.24       261\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1200\n",
      "   macro avg       0.56      0.54      0.54      1200\n",
      "weighted avg       0.70      0.74      0.71      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm = LogisticRegression()\n",
    "lm = lm.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using Random Forest model\n",
    "pred = lm.predict(x_test1_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary = np.mean(pred == y_test1)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7816666666666666\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred2 = lm.predict(x_test2_tfidf)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary = np.mean(pred2 == y_test2)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                        Language Education Time COVID-19\n",
      "1                                      COVID-19 Test Kits\n",
      "2                                      COVID 19 IN PRISON\n",
      "3                                          Get Waled Home\n",
      "4       Make pass/fail available Mississippi State Stu...\n",
      "5       Governor Doug Burgum Issue Mandatory Shelter-i...\n",
      "6                              Early release due covid 19\n",
      "7       Medical professionals need protection gear fig...\n",
      "8       Save Gilroy Recreation - Theater, Aquatics, Pr...\n",
      "9                            Class 2020 get certification\n",
      "10      Calling Disability- Inclusive Response Covid-1...\n",
      "11      Open 2020-2021 School Year Traditionally Shast...\n",
      "12      Save Enhanced Nursery School Operating Grant!!...\n",
      "13                Cancel STAAR test 2020/2021 school year\n",
      "14                            Justice For Dr. Susan Moore\n",
      "15                     Extend Winter Break Brock Students\n",
      "16                        Get American crew members home!\n",
      "17                       RAISE PSW WAGES TO $25â€‹.â€‹00/HOUR\n",
      "18       COVID-19 Dance Studio Industry Economic Hardship\n",
      "19                             Support More Testing Covid\n",
      "20                             UBC Partial Tuition Refund\n",
      "21                   Close Chinaâ€™s wet market permanently\n",
      "22                                          #SaveOurYouth\n",
      "23                       Tuition Adjustments Due COVID-19\n",
      "24      Ensure Education. STOP HIKE School Fee 2020-20...\n",
      "25                        Cancel 10th Gujarat Board Exams\n",
      "26      Cancellation University assignments exams due ...\n",
      "27            NEU- CLOSE CAMPUS AND START ONLINE TEACHING\n",
      "28      NOW reinstate facial treatments behind side face.\n",
      "29                               Equestrian Riding relief\n",
      "                              ...                        \n",
      "1470                               Covid-19 vs. Prisoners\n",
      "1471          Close New Jersey schools due COVID-19 virus\n",
      "1472    Launch COVID-19 Vaccination Program West Bank ...\n",
      "1473                          Local Fire Sirens - heard!!\n",
      "1474                  SAVE THE PORTLAND CHILDREN'S MUSEUM\n",
      "1475       6 Demands NHS staff help us tackle Coronavirus\n",
      "1476             Make 0% Interest Student Loans Permanent\n",
      "1477    Full Lockdown government Malaysia due Covid 19...\n",
      "1478    Support fair pay NZ's aged care nurses - PETIT...\n",
      "1479    Rollins College's Spring Semester changed PASS...\n",
      "1480                       RESCHEDULING OF IIE GRADUATION\n",
      "1481    Justice 89-year-old Asian American Hate Crime ...\n",
      "1482    India - Immediately Designate Private Hospital...\n",
      "1483                                         Save saviors\n",
      "1484                         Save John Lewis Peterborough\n",
      "1485    Reduce 4700 rm quarantine charges home quarant...\n",
      "1486          Shut Down All Bâ€‹.â€‹C Schools Due To Covid-19\n",
      "1487    Hold Town Sports International Holdings financ...\n",
      "1488    Reduce OSU tuition-and-fees cost response COVI...\n",
      "1489    Government must honor Doctors & Frontline Work...\n",
      "1490                    RECALL TEXAS GOVERNOR GREG ABBOTT\n",
      "1491                   A second stimulus check Americans!\n",
      "1492    COVID-19 Single parents guardians minors must ...\n",
      "1493                               Rapid testing COVID-19\n",
      "1494    uOttawa Make Pass/Fail Option Classes Winter S...\n",
      "1495                             Null void Premier League\n",
      "1496    Free public transport NHS staff accompany 1% p...\n",
      "1497    PM please give immediate COVID Insurance cover...\n",
      "1498               SAY NO TO OSHA PROPOSED PERMANENT RULE\n",
      "1499                 (NTU) - Viewing results deciding S/U\n",
      "Name: text, Length: 1500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing - stop word filtering\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "set(stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "mask_data1['text'] = mask_data1['text'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop_words)]))\n",
    "print(mask_data1[\"text\"])\n",
    "mask_data2['text'] = mask_data2['text'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Putin After Announcing #CovidVaccine #Russian ...\n",
      "1       Courtesy: WA! #WhatsApp #COVID #CovidVaccine h...\n",
      "2       4 vaccines Jared bought expected fail Trump re...\n",
      "3       One day realize CDC Guidelines magically align...\n",
      "4       Im far lying. Current CDC guidelines wearing m...\n",
      "5       Russiaâ€™s Covid vaccine â€˜Sputnik-Vâ€™ might relea...\n",
      "6       I donâ€™t see masks. In fact, child thereâ€¦and re...\n",
      "7       I fully vaccinated, unless CDC guidelines chan...\n",
      "8       ask every single person walks know need wear m...\n",
      "9       sense touch 40k #CovidVaccine released unregul...\n",
      "10      Health ministry approval Covid vaccine Russia ...\n",
      "11      10 Days Onam names | kerala https://t.co/A2nX9...\n",
      "12      amazing review insights #vaccine experts I hig...\n",
      "13      Pretty sure people wearing masks right vaccina...\n",
      "14      These patients slowly tortured fully tortured ...\n",
      "15      Safety &amp efficacy #CovidVaccine must follow...\n",
      "16      unveils online platform ease #CovidVaccine #su...\n",
      "17          One reason CDC mask guidelines reprehensible.\n",
      "18      I love heâ€™s saying â€œI donâ€™t believe science va...\n",
      "19      Russia becomes first country register coronavi...\n",
      "20      Chinaâ€™s Sinovac Biotech plans start clinical t...\n",
      "21      That's mayor says city still following guideli...\n",
      "22      I follow CDC guidelines fully vaccinated I'm m...\n",
      "23      Hey care explain board voted tonight go CDC gu...\n",
      "24      Watchout, today #newzealand outbreak five matc...\n",
      "25      After getting COVID-19 waiting 3 months (per C...\n",
      "26      Must read summary #CovidVaccine development. M...\n",
      "27      CREWNY's top priority remains health safety me...\n",
      "28      Experience 4, Medicaid (ACA) fights pay pain m...\n",
      "29      This type dishonest health communication many ...\n",
      "                              ...                        \n",
      "1170    \"the 2016 CDC Guidelines consequently flawed b...\n",
      "1171    We've already established chartered flight fel...\n",
      "1172    China displays Covid-19 vaccines first time ht...\n",
      "1173    Worldwide Flight Services (WFS) launched Proje...\n",
      "1174    Four China-origin COVID-19 vaccines ready phas...\n",
      "1175    itâ€™s busy weekend instagram graphic designer w...\n",
      "1176    What China's Covid-19 vaccine comes market fir...\n",
      "1177    So many Infectious Disease DOCTORS stated full...\n",
      "1178    Exciting news - barring last minute safety iss...\n",
      "1179    No probably long they're following cdc guideli...\n",
      "1180    PM Modi Updates On Covid #Vaccine: '3 In Testi...\n",
      "1181    Cats could help researchers unlock COVID-19 va...\n",
      "1182    He's following CDC guidelines wash hands getti...\n",
      "1183    FINALLY shutdown, would greatly help try &amp;...\n",
      "1184    #Bubbles form existence pure play investment o...\n",
      "1185    But followed CDC local guidelines fully vaxxed...\n",
      "1186    Will ready 2020....? #covid19 #pandemic #coron...\n",
      "1187    Dr Daisy Fancourt, leads Britainâ€™s largest stu...\n",
      "1188    ðŸš¨Breaking Newz They're pay people #Covid tests...\n",
      "1189    #covidvaccine stocks current lull clinical res...\n",
      "1190    Pfizer's potential #CovidVaccine one three bac...\n",
      "1191    This new. BBC News - Covid airborne, US CDC gu...\n",
      "1192    7 looming questions rollout Covid-19 vaccine #...\n",
      "1193    Dr. Lewis, following revision CDC pain Guideli...\n",
      "1194    Union Health Minister Harsh Vardhan Thursday s...\n",
      "1195    .Sprint To Develop A #COVIDVaccine â€“ // https:...\n",
      "1196    Here U.S. localities brought back mask mandate...\n",
      "1197    Sanitizer &amp; Mask Manufacturers After Russi...\n",
      "1198    We following CDC guidelines combination regula...\n",
      "1199    People losing hopes covid vaccine like 4g kash...\n",
      "Name: text, Length: 1200, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(mask_data2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_score\n",
    "\n",
    "#precision_pri1 = precision_score(y_test1, pred)\n",
    "#print(precision_pri1)\n",
    "#precision_sec2 = precision_score(y_test2, pred2)\n",
    "#print(precision_sec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4] Feature Engineering\n",
    "#adding a new feature - sentiment feature\n",
    "#from textblob import TextBlob\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Polarity range lies between -1 to 1. -1 means negative sentiment and 1 means positive sentiment\n",
    "#def getPolarity(text):\n",
    "#    polarity = TextBlob(text).sentiment.polarity\n",
    "#    scaled_mat = (polarity - np.min(polarity) / (np.max(polarity) - np.min(polarity)) * (1 - 0) + 0)\n",
    "#    scaler = MinMaxScaler()\n",
    "#    return scaled_mat\n",
    "#    return scaler.fit_transform(polarity)\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#mask_data1[\"sentiment\"] = mask_data1[\"text\"].apply(getPolarity)\n",
    "#mask_data1.head()\n",
    "#print(mask_data1[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(mask_data1[\"sentiment\"], mask_data1[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4] Feature Engineering\n",
    "#adding a new feature - whether the text contains hashtag\n",
    "\n",
    "import re\n",
    "\n",
    "def hashtag_feature(text):\n",
    "    return int(bool(re.search(\"#\\w+\", text)))\n",
    "\n",
    "mask_data1[\"hashtag\"] = mask_data1[\"text\"].apply(hashtag_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mask_data1[\"hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(mask_data1.loc[924].at[\"hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Education Time COVID-19</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Test Kits</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID 19 IN PRISON</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get Waled Home</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make pass/fail available Mississippi State Stu...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  hashtag  \\\n",
       "0                   Language Education Time COVID-19  False        0   \n",
       "1                                 COVID-19 Test Kits  False        0   \n",
       "2                                 COVID 19 IN PRISON  False        0   \n",
       "3                                     Get Waled Home  False        0   \n",
       "4  Make pass/fail available Mississippi State Stu...  False        0   \n",
       "\n",
       "   word_count  \n",
       "0           4  \n",
       "1           3  \n",
       "2           4  \n",
       "3           3  \n",
       "4           9  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding 2nd feature - length feature\n",
    "from textblob import TextBlob\n",
    "\n",
    "mask_data1['word_count'] = mask_data1[\"text\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "#Polarity range lies between -1 to 1. -1 means negative sentiment and 1 means positive sentiment\n",
    "#def getPolarity(text):\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#mask_data1[\"sentiment\"] = mask_data1[\"text\"].apply(getPolarity)\n",
    "mask_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 3rd feature - pattern for detecting the text where COVID is referred\n",
    "def pattern_detection(text):\n",
    "    return int(bool(re.search(\"COVID\", text, flags = re.I)))\n",
    "\n",
    "mask_data1[\"pattern\"] = mask_data1[\"text\"].apply(pattern_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(mask_data1[\"pattern\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(mask_data1.loc[888].at[\"pattern\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 4th feature - pattern for detecting the text where words like close, cancel along with COVID are used which imply actions taken for social distancing\n",
    "def pattern_detection2(text):\n",
    "#    return int(bool(re.search(\"(close|cancel.*|shut|postpone.*)\\s[\\w\\s]+COVID\", text, flags = re.I)))\n",
    "    return int(bool(re.search(\"(close|cancel.*|shut|postpone.*)\\s[\\w\\s]+COVID\", text, flags = re.I)))\n",
    "mask_data1[\"pattern2\"] = mask_data1[\"text\"].apply(pattern_detection2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "7       0\n",
      "8       0\n",
      "9       0\n",
      "10      0\n",
      "11      0\n",
      "12      0\n",
      "13      0\n",
      "14      0\n",
      "15      0\n",
      "16      0\n",
      "17      0\n",
      "18      0\n",
      "19      0\n",
      "20      0\n",
      "21      0\n",
      "22      0\n",
      "23      0\n",
      "24      0\n",
      "25      0\n",
      "26      1\n",
      "27      0\n",
      "28      0\n",
      "29      0\n",
      "       ..\n",
      "1470    0\n",
      "1471    1\n",
      "1472    0\n",
      "1473    0\n",
      "1474    0\n",
      "1475    0\n",
      "1476    0\n",
      "1477    0\n",
      "1478    0\n",
      "1479    0\n",
      "1480    0\n",
      "1481    0\n",
      "1482    0\n",
      "1483    0\n",
      "1484    0\n",
      "1485    0\n",
      "1486    0\n",
      "1487    0\n",
      "1488    0\n",
      "1489    0\n",
      "1490    0\n",
      "1491    0\n",
      "1492    0\n",
      "1493    0\n",
      "1494    0\n",
      "1495    0\n",
      "1496    0\n",
      "1497    0\n",
      "1498    0\n",
      "1499    0\n",
      "Name: pattern2, Length: 1500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mask_data1[\"pattern2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 5th feature - count the number of capital words in a text\n",
    "\n",
    "def capital_words(text):\n",
    "    return sum(map(str.isupper, text.split()))\n",
    "\n",
    "mask_data1[\"capital_count\"] = mask_data1[\"text\"].apply(capital_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(mask_data1.loc[286].at[\"pattern2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern2</th>\n",
       "      <th>capital_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Education Time COVID-19</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Test Kits</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID 19 IN PRISON</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get Waled Home</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make pass/fail available Mississippi State Stu...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  hashtag  \\\n",
       "0                   Language Education Time COVID-19  False        0   \n",
       "1                                 COVID-19 Test Kits  False        0   \n",
       "2                                 COVID 19 IN PRISON  False        0   \n",
       "3                                     Get Waled Home  False        0   \n",
       "4  Make pass/fail available Mississippi State Stu...  False        0   \n",
       "\n",
       "   word_count  pattern  pattern2  capital_count  \n",
       "0           4        1         0              1  \n",
       "1           3        1         0              1  \n",
       "2           4        1         0              3  \n",
       "3           3        0         0              0  \n",
       "4           9        0         0              0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern2</th>\n",
       "      <th>capital_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Education Time COVID-19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Test Kits</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID 19 IN PRISON</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get Waled Home</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make pass/fail available Mississippi State Stu...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hashtag  word_count  \\\n",
       "0                   Language Education Time COVID-19        0           4   \n",
       "1                                 COVID-19 Test Kits        0           3   \n",
       "2                                 COVID 19 IN PRISON        0           4   \n",
       "3                                     Get Waled Home        0           3   \n",
       "4  Make pass/fail available Mississippi State Stu...        0           9   \n",
       "\n",
       "   pattern  pattern2  capital_count  label  \n",
       "0        1         0              1  False  \n",
       "1        1         0              1  False  \n",
       "2        1         0              3  False  \n",
       "3        0         0              0  False  \n",
       "4        0         0              0  False  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data1 = mask_data1[[\"text\", \"hashtag\", \"word_count\", \"pattern\", \"pattern2\",\"capital_count\", \"label\"]]\n",
    "mask_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitting the primary dataset into train and test sets\n",
    "x_train2, x_test3, y_train2, y_test3 = train_test_split(mask_data1[[\"text\", \"hashtag\", \"word_count\", \"pattern\", \"pattern2\", \"capital_count\"]],mask_data1[\"label\"], test_size=0.3, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 2960)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bag-of-words\n",
    "count_vect2 = CountVectorizer()\n",
    "x_train2_counts = count_vect2.fit_transform(x_train2[\"text\"])\n",
    "x_train2_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect2.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 2960)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf-idf\n",
    "tfidf = TfidfTransformer()\n",
    "x_train2_tfidf = tfidf.fit_transform(x_train2_counts)\n",
    "x_train2_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 2965)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding 5 new features to train \n",
    "#x_train2_final = np.insert(x_train2_tfidf.todense(), x_train2_tfidf.shape[1], x_train2[\"sentiment\"], axis=1)\n",
    "x_train2_final = np.insert(x_train2_tfidf.todense(), x_train2_tfidf.shape[1], x_train2[\"hashtag\"], axis=1)\n",
    "x_train2_final = np.insert(x_train2_final, x_train2_final.shape[1], x_train2[\"word_count\"], axis=1)\n",
    "x_train2_final = np.insert(x_train2_final, x_train2_final.shape[1], x_train2[\"pattern\"], axis=1)\n",
    "x_train2_final = np.insert(x_train2_final, x_train2_final.shape[1], x_train2[\"pattern2\"], axis=1)\n",
    "x_train2_final = np.insert(x_train2_final, x_train2_final.shape[1], x_train2[\"capital_count\"], axis=1)\n",
    "x_train2_final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 2960)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf-idf on test data(primary)\n",
    "x_test3_counts = count_vect2.transform(x_test3[\"text\"])\n",
    "x_test3_tfidf = tfidf.transform(x_test3_counts)\n",
    "x_test3_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 2965)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding 5 new features to test(primary)\n",
    "#x_test3_final = np.insert(x_test3_tfidf.todense(), x_test3_tfidf.shape[1], x_test3[\"sentiment\"], axis=1)\n",
    "x_test3_final = np.insert(x_test3_tfidf.todense(), x_test3_tfidf.shape[1], x_test3[\"hashtag\"], axis=1)\n",
    "x_test3_final = np.insert(x_test3_final, x_test3_final.shape[1], x_test3[\"word_count\"], axis=1)\n",
    "x_test3_final = np.insert(x_test3_final, x_test3_final.shape[1], x_test3[\"pattern\"], axis=1)\n",
    "x_test3_final = np.insert(x_test3_final, x_test3_final.shape[1], x_test3[\"pattern2\"], axis=1)\n",
    "x_test3_final = np.insert(x_test3_final, x_test3_final.shape[1], x_test3[\"capital_count\"], axis=1)\n",
    "x_test3_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern2</th>\n",
       "      <th>capital_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Putin After Announcing #CovidVaccine #Russian ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Courtesy: WA! #WhatsApp #COVID #CovidVaccine h...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 vaccines Jared bought expected fail Trump re...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One day realize CDC Guidelines magically align...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im far lying. Current CDC guidelines wearing m...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hashtag  word_count  \\\n",
       "0  Putin After Announcing #CovidVaccine #Russian ...        1           6   \n",
       "1  Courtesy: WA! #WhatsApp #COVID #CovidVaccine h...        1           6   \n",
       "2  4 vaccines Jared bought expected fail Trump re...        0          11   \n",
       "3  One day realize CDC Guidelines magically align...        0          10   \n",
       "4  Im far lying. Current CDC guidelines wearing m...        0          13   \n",
       "\n",
       "   pattern  pattern2  capital_count  label  \n",
       "0        1         0              0  False  \n",
       "1        1         0              2  False  \n",
       "2        0         0              0  False  \n",
       "3        0         0              1  False  \n",
       "4        0         0              1   True  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a new feature - sentiment feature to test data\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Polarity range lies between -1 to 1. -1 means negative sentiment and 1 means positive sentiment\n",
    "#def getPolarity(text):\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#mask_data2[\"sentiment\"] = mask_data2[\"text\"].apply(getPolarity)\n",
    "mask_data2[\"hashtag\"] = mask_data2[\"text\"].apply(hashtag_feature)\n",
    "mask_data2['word_count'] = mask_data2[\"text\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "mask_data2[\"pattern\"] = mask_data2[\"text\"].apply(pattern_detection)\n",
    "mask_data2[\"pattern2\"] = mask_data2[\"text\"].apply(pattern_detection2)\n",
    "mask_data2[\"capital_count\"] = mask_data2[\"text\"].apply(capital_words)\n",
    "mask_data2 = mask_data2[[\"text\", \"hashtag\", \"word_count\", \"pattern\", \"pattern2\",\"capital_count\", \"label\"]]\n",
    "mask_data2.head()\n",
    "#print(mask_data1[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using full secondary dataset as test dataset\n",
    "x_test4 = mask_data2[[\"text\", \"hashtag\", \"word_count\", \"pattern\", \"pattern2\", \"capital_count\"]]\n",
    "y_test4 = mask_data2[\"label\"] == 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 2960)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf-idf on test data(secondary)\n",
    "x_test4_counts = count_vect2.transform(x_test4[\"text\"])\n",
    "x_test4_tfidf = tfidf.transform(x_test4_counts)\n",
    "x_test4_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 2965)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding 5 new features to test(secondary)\n",
    "#x_test4_final = np.insert(x_test4_tfidf.todense(), x_test4_tfidf.shape[1], x_test4[\"sentiment\"], axis=1)\n",
    "x_test4_final = np.insert(x_test4_tfidf.todense(), x_test4_tfidf.shape[1], x_test4[\"hashtag\"], axis=1)\n",
    "x_test4_final = np.insert(x_test4_final, x_test4_final.shape[1], x_test4[\"word_count\"], axis=1)\n",
    "x_test4_final = np.insert(x_test4_final, x_test4_final.shape[1], x_test4[\"pattern\"], axis=1)\n",
    "x_test4_final = np.insert(x_test4_final, x_test4_final.shape[1], x_test4[\"pattern2\"], axis=1)\n",
    "x_test4_final = np.insert(x_test4_final, x_test4_final.shape[1], x_test4[\"capital_count\"], axis=1)\n",
    "x_test4_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset after adding new features is\n",
      "0.7155555555555555\n"
     ]
    }
   ],
   "source": [
    "#using Naive Bayes \n",
    "\n",
    "nb2 = MultinomialNB().fit(x_train2_final, y_train2)\n",
    "pred3 = nb2.predict(x_test3_final)\n",
    "\n",
    "#performance evaluation with primary test dataset after adding new features\n",
    "\n",
    "accu_primary2 = np.mean(pred3 == y_test3)\n",
    "\n",
    "print(\"Accuracy of primary test dataset after adding new features is\")\n",
    "print(accu_primary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7825\n"
     ]
    }
   ],
   "source": [
    "pred4 = nb2.predict(x_test4_final)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary2 = np.mean(pred4 == y_test4)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "print(y_test4.dtype)\n",
    "print(pred4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      1.00      0.83       313\n",
      "        True       1.00      0.07      0.12       137\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       450\n",
      "   macro avg       0.85      0.53      0.48       450\n",
      "weighted avg       0.80      0.72      0.62       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test3, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      1.00      0.88       939\n",
      "        True       0.00      0.00      0.00       261\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1200\n",
      "   macro avg       0.39      0.50      0.44      1200\n",
      "weighted avg       0.61      0.78      0.69      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test4, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#using SVM model on training data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm2 = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None).fit(x_train2_final, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using SVM model for primary dataset \n",
    "pred3 = svm2.predict(x_test3_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.7933333333333333\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary2 = np.mean(pred3 == y_test3)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7816666666666666\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred4 = svm2.predict(x_test4_final)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary2 = np.mean(pred4 == y_test4)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test3, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test4, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators = 1, random_state = 42)\n",
    "rf2 = rf2.fit(x_train2_final, y_train2)\n",
    "\n",
    "#the accuracy kept on decreasing if number of estimators were increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using Random Forest model\n",
    "pred3 = rf2.predict(x_test3_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.7688888888888888\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary2 = np.mean(pred3 == y_test3)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred4 = rf2.predict(x_test4_final)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary2 = np.mean(pred4 == y_test4)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.87      0.84       313\n",
      "        True       0.64      0.55      0.59       137\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       450\n",
      "   macro avg       0.73      0.71      0.71       450\n",
      "weighted avg       0.76      0.77      0.76       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test3, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.86      0.82       939\n",
      "        True       0.24      0.15      0.19       261\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1200\n",
      "   macro avg       0.51      0.51      0.51      1200\n",
      "weighted avg       0.67      0.71      0.69      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test4, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm2 = LogisticRegression()\n",
    "lm2 = lm2.fit(x_train2_final, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using Logistic Regression model\n",
    "pred3 = lm2.predict(x_test3_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of primary test dataset is\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with primary test dataset\n",
    "\n",
    "accu_primary2 = np.mean(pred3 == y_test3)\n",
    "#print(pred)\n",
    "#print(y_test1)\n",
    "print(\"Accuracy of primary test dataset is\")\n",
    "print(accu_primary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of secondary test dataset is\n",
      "0.7816666666666666\n"
     ]
    }
   ],
   "source": [
    "#performance evaluation with sceondary dataset\n",
    "\n",
    "pred4 = lm2.predict(x_test4_final)\n",
    "#print(pred2)\n",
    "#print(y_test2)\n",
    "accu_secondary2 = np.mean(pred4 == y_test4)\n",
    "print(\"Accuracy of secondary test dataset is\")\n",
    "print(accu_secondary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, I have implemented 4 classification models both before feature engineering and after feature engineering.\n",
    "\n",
    "Before feature engineering:\n",
    "Accuracy of primary test dataset\n",
    "Naive Bayes - 75.55%\n",
    "SVM - 81.77%\n",
    "Random Forest - 75.33%\n",
    "Logistic Regression - 78%\n",
    "\n",
    "Accuracy of secondary test dataset\n",
    "Naive Bayes - 78.25%\n",
    "SVM - 77.16%\n",
    "Random Forest - 73.75%\n",
    "Logistic Regression - 78.16%\n",
    "\n",
    "Accuracy of primary test dataset\n",
    "Naive Bayes - 71.55%\n",
    "SVM - 79.33%\n",
    "Random Forest - 76.88%\n",
    "Logistic Regression - 78%\n",
    "\n",
    "Accuracy of secondary test dataset\n",
    "Naive Bayes - 78.25%\n",
    "SVM - 78.16%\n",
    "Random Forest - 71%\n",
    "Logistic Regression - 78.16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
